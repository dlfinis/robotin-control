# Robotin Control - Environment Configuration
# Copy this file to .env.local and fill in your API keys

# ============================================================================
# Data Directories
# ============================================================================

ROBOTIN_DATA_DIR=./data
ROBOTIN_PROJECTS_DIR=./data/projects
ROBOTIN_LANCEDB_PATH=./data/lance
ROBOTIN_CACHE_PATH=./data/cache

# ============================================================================
# Database
# ============================================================================

DATABASE_PATH=./data/robotin.db

# ============================================================================
# Logging (trace, debug, info, warn, error, fatal)
# ============================================================================

ROBOTIN_LOG_LEVEL=info

# ============================================================================
# LLM Providers (OpenAI-Compatible)
# Priority: LM Studio (local) > DeepSeek > Kimi > OpenAI
# ============================================================================

# LM Studio (local) - Primary provider
# Download: https://lmstudio.ai
# Start server and load a model, then verify: http://localhost:1234/v1/models
LM_STUDIO_HOST=http://localhost:1234
LM_STUDIO_MODEL=local-model

# DeepSeek API - Cheapest option (~90% cheaper than OpenAI)
# Get API key: https://platform.deepseek.com/
# Pricing: $0.28/1M input, $0.42/1M output tokens
# Uncomment and fill to enable:
# DEEPSEEK_API_KEY=sk-your-deepseek-key-here
# DEEPSEEK_MODEL=deepseek-chat

# Kimi API (Moonshot) - Best long context (256K tokens)
# Get API key: https://platform.moonshot.cn/
# Pricing: ~$0.50/1M input, ~$1.50/1M output tokens
# Uncomment and fill to enable:
# KIMI_API_KEY=sk-your-kimi-key-here
# KIMI_MODEL=kimi-k2.5

# OpenAI API - Fallback option
# Get API key: https://platform.openai.com/
# Pricing: $2.50/1M input, $10.00/1M output tokens (GPT-4o)
# Uncomment and fill to enable:
# OPENAI_API_KEY=sk-your-openai-key-here
# OPENAI_MODEL=gpt-3.5-turbo

# ============================================================================
# Embeddings
# ============================================================================

# Current: all-MiniLM-L6-v2 (80MB, fast, English only)
# Alternative for multilingual: Xenova/bge-m3 (2.2GB, SOTA)
EMBEDDING_MODEL=Xenova/all-MiniLM-L6-v2
EMBEDDING_DIMENSIONS=384

# ============================================================================
# API Server
# ============================================================================

API_PORT=3000
API_HOST=localhost

# ============================================================================
# Processing
# ============================================================================

CHUNK_SIZE=512
CHUNK_OVERLAP=50
